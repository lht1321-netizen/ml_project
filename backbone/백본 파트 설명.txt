<백본 파트 역할>
우리 모델 Mask2Former에서 백본의 역할은, 입력된 항공사진(.tif)으로부터 다양한 수준의 특징 정보(Feature Maps)를 추출하여, 후속 모듈인 픽셀 디코더(Pixel Decoder)와 트랜스포머 디코더(Transformer Decoder)로 전달하는 것입니다.​

<최종 구현 코드 및 결과>
아래 코드는 우리 프로젝트의 데이터를 사용하여 백본(Swin Transformer)을 실행하고, 그 결과물을 확인하는 최종 코드입니다.


[핵심 코드 로직]
데이터셋 정의 (BuildingDataset 클래스)
항공사진(.tif)과 우리가 전처리하여 생성한 건물 라벨(.npy)을 한 쌍으로 묶어 불러옵니다
메모리 문제를 해결하고 모델 학습 효율을 높이기 위해, 거대한 원본 이미지를 일정한 크기(512x512)로 리사이즈하고 정규화하는 전처리 과정을 포함했습니다.
2. 모델 로드 및 백본 추출
Hugging Face의 사전 학습된 Mask2FormerForUniversalSegmentation 모델을 불러옵니다.
모델 내부에서 실제 특징 추출을 담당하는 SwinBackbone 부분만 정확히 추출하여 사용합니다.
3. 백본 실행 및 특징 맵 추출
전처리된 이미지 데이터를 백본에 입력하여, 최종 결과물인 **다중 스케일 특징 맵(Multi-scale Feature Maps)**을 성공적으로 추출했습니다.


[실행 결과]
데이터 로더에서 첫 번째 이미지 배치(형태: torch.Size([1, 3, 512, 512]))를 가져왔습니다.
Swin Transformer 백본이 추출한 다중 스케일 특징 맵:
  - Stage 0 특징 맵 형태: torch.Size([1, 16384, 128])
  - Stage 1 특징 맵 형태: torch.Size([1, 16384, 128])
  - Stage 2 특징 맵 형태: torch.Size([1, 4096, 256])
  - Stage 3 특징 맵 형태: torch.Size([1, 1024, 512])
  - Stage 4 특징 맵 형태: torch.Size([1, 256, 1024])

-> 결과물의 의미: 픽셀 디코더와 트랜스포머 디코더로 전달될 데이터
위 결과에서 Swin Transformer 백본이 추출한 다중 스케일 특징 맵이 backbone 파트의 최종 결과물이며, 다른 파트로 전달될 입력 데이터입니다.

다중 스케일(Multi-scale)의 의미: 이 특징 맵들은 하나의 이미지를 다양한 관점에서 분석한 결과물입니다.​
-초기 Stage (고해상도): 이미지의 세밀한 경계선, 모서리 등 '디테일' 정보를 담고 있습니다.
-후기 Stage (저해상도): 이미지의 전체적인 구조, 객체의 형태 등 '맥락' 정보를 담고 있습니다.
팀원 파트와의 연관성:
-픽셀 디코더 파트:  다중 스케일 특징 맵들(hidden_states)을 입력으로 받아, 이를 다시 융합하고 업샘플링하여 최종 마스크를 예측하는 데 필요한 고해상도의 픽셀별 임베딩(per-pixel embeddings)을 생성하게 됩니다.​
-트랜스포머 디코더 파트:  이 특징 맵들과 학습 가능한 쿼리(queries)를 함께 사용하여, 이미지에 어떤 객체들이 있는지, 그리고 각 객체가 어떤 픽셀들을 포함하는지에 대한 정보를 추출하게 됩니다.​

<결론 및 다음 단계>
여기서 구현한 코드의 hidden_states 변수가 다른 파트의 모듈로 전달될 입력 데이터이니, 이를 기반으로 파트 연동을 준비해 주시면 됩니다.