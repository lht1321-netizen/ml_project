<백본 파트 전처리 - 이미지 및 라벨 리사이징 구현 설명>

모델의 안정적인 실행과 성능 향상을 위해 필요한 이미지 및 라벨 리사이징(Resizing) 전처리 과정을 `BuildingDataset` 클래스에 구현했습니다. 

1. 리사이징이 필요한 이유
우리가 사용하는 항공사진 원본(`.tif`)은 `10000x10000` 픽셀이 넘는 초고해상도 이미지입니다. 이 이미지를 그대로 모델에 입력하면 두 가지 큰 문제가 발생합니다.

*   메모리 부족 (Out of Memory): 초고해상도 이미지는 엄청난 양의 GPU 메모리를 차지합니다. 이로 인해 학습 과정에서 'CUDA out of memory' 오류가 발생하여 모델 실행 자체가 불가능해집니다.
*   비효율적인 학습: 우리가 사용하는 Mask2Former 모델은 `512x512` 와 같은 비교적 작은 크기의 이미지들로 사전 학습되었습니다. 원본 크기 그대로 입력하면 모델이 특징을 효과적으로 잡아내기 어렵습니다.

이 문제들을 해결하기 위해, 모든 이미지를 일정한 소형 크기(예: 512x512)로 통일시키는 리사이징 과정이 필수적입니다.



2. 어떻게 구현했나?(`BuildingDataset` 클래스)
`__getitem__` 메소드 안에서 `torchvision.transforms.functional` (줄여서 `F`)을 사용하여 리사이징을 구현했습니다. 여기서 가장 중요한 점은 **이미지와 라벨을 서로 다른 방식으로 리사이즈**해야 한다는 것입니다.

->코드 내용
# torchvision.transforms.functional을 F로 줄여서 사용
import torchvision.transforms.functional as F

# ... __getitem__ 메소드 내부 ...

# (1) 이미지 리사이즈: BILINEAR 보간법 사용
image_tensor = F.resize(image_tensor, self.resize_shape, interpolation=F.InterpolationMode.BILINEAR)

# (2) 라벨(마스크) 리사이즈: NEAREST 보간법 사용
label_tensor = F.resize(label_tensor, self.resize_shape, interpolation=F.InterpolationMode.NEAREST)
```



3. 두 가지 리사이즈 방식의 차이점
*   `BILINEAR` (이미지용):
    - 동작 방식: 픽셀을 줄일 때, 주변 픽셀들의 색상 값을 부드럽게 섞어서(보간하여) 새로운 픽셀 값을 만듭니다.
    - 결과: 이미지의 계단 현상(aliasing)이 줄어들어 시각적으로 더 자연스럽고 부드럽게 축소됩니다.

*   `NEAREST` (라벨/마스크용):
    - 동작 방식: 주변 픽셀을 섞지 않고, 새로운 위치에서 가장 가까운 원본 픽셀의 값을 그대로 가져옵니다.
    - 결과: 라벨(마스크)의 값은 '0(배경)', '1(건물)'과 같이 각 영역을 구분하는 **정수 ID**입니다. 만약 `BILINEAR` 방식을 사용하면 '0'과 '1'이 섞여 '0.7'과 같은 의미 없는 소수점 값이 생길 수 있습니다. `NEAREST` 방식은 이러한 문제를 방지하고, 리사이즈 후에도 라벨 값이 정수 ID로 명확하게 유지되도록 보장합니다.[1][3]





[결론]
백본 파트의 `BuildingDataset` 내부에 위와 같은 리사이징 로직을 구현함으로써,
1.  메모리 부족 문제를 근본적으로 해결했습니다.
2.  모델이 더 안정적이고 효율적으로 학습할 수 있는 환경을 마련했습니다.
3.  이미지 분할(Segmentation) 작업의 특성을 고려하여, 이미지와 라벨에 각기 다른 보간법을 적용하는 올바른 전처리 파이프라인을 구축했습니다.


